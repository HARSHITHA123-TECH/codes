import pandas as pd
import numpy as np
import tensorflow as tf
from sklearn.preprocessing import MinMaxScaler
import pickle
from datetime import datetime, timedelta
class PicklableModel:
    def __init__(self, model):
        self.model = model

    def __getstate__(self):
        return self.model.to_json()

    def __setstate__(self, state):
        self.model = tf.keras.models.model_from_json(state)

    def predict(self, input_data):
        return self.model.predict(input_data)

# Step 1: Parse the dates
from_date = datetime.strptime('2024-04-21', '%Y-%m-%d')
to_date = datetime.strptime('2024-04-25', '%Y-%m-%d')

# Step 2: Generate the date range
date_range = [from_date + timedelta(days=x) for x in range((to_date - from_date).days + 1)]

# Step 3: Create a new DataFrame from the date range
new_dates_df = pd.DataFrame(data={"time_stamp": date_range})

# Step 4: Apply the transformations to new_dates_df
new_dates_df["Month"] = pd.to_datetime(new_dates_df["time_stamp"]).dt.month
new_dates_df["Year"] = pd.to_datetime(new_dates_df["time_stamp"]).dt.year
new_dates_df["Date"] = pd.to_datetime(new_dates_df["time_stamp"]).dt.date
new_dates_df["Time"] = pd.to_datetime(new_dates_df["time_stamp"]).dt.time
new_dates_df["Week"] = pd.to_datetime(new_dates_df["time_stamp"]).dt.isocalendar().week
new_dates_df["Day"] = pd.to_datetime(new_dates_df["time_stamp"]).dt.day_name()

# Step 5: Set 'Datetime' as index and ensure it's datetime type
new_dates_df = new_dates_df.set_index("time_stamp")
new_dates_df.index = pd.to_datetime(new_dates_df.index)

# Load the dataset and preprocess
df = pd.read_csv("AEP_hourly.csv")
df['time_stamp'] = pd.to_datetime(df['time_stamp'])
df.set_index("time_stamp", inplace=True)

# Resample the dataset to daily means
NewDataSet = df.resample('D').mean()

# Extract the last 100 days as TestData
TestData = NewDataSet.tail(100)

# Step 6: Append the transformed new_dates_df to TestData with NaN for AEP_MW
new_dates_df["result"] = np.nan  # Add a placeholder column for 'AEP_MW'
TestData = pd.concat([TestData, new_dates_df], ignore_index=False)

# Remove the starting values of length equal to the number of days in the date range from TestData
num_days_in_date_range = len(date_range)
TestData = TestData.iloc[num_days_in_date_range:]

# Prepare the data for prediction
Df_Total = pd.concat((NewDataSet[["result"]], TestData[["result"]]), axis=0)
inputs = Df_Total[len(Df_Total) - len(TestData) - 60:].values

# Normalize the dataset
sc = MinMaxScaler(feature_range=(0, 1))
inputs = inputs.reshape(-1, 1)
inputs = sc.fit_transform(inputs)

# Prepare the test data for the model
X_test = []
for i in range(60, len(inputs)):
    X_test.append(inputs[i-60:i])

# Convert into Numpy Array
X_test = np.array(X_test)

# Reshape before passing to the network
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Load the trained model
with open(r'C:\Pickle\model.pkl', 'rb') as f:
    picklable_model = pickle.load(f)

# Predict
predicted_stock_price = picklable_model.predict(X_test)

# Inverse transform to get values
predicted_stock_price = sc.inverse_transform(predicted_stock_price)

# Prepare the final DataFrame with results
True_MegaWatt = TestData["result"].to_list()
dates = TestData.index.to_list()

# Debugging: Print lengths of key variables
print(f"Length of TestData: {len(TestData)}")
print(f"Length of predicted_stock_price: {len(predicted_stock_price)}")

# Initialize Predicted_MegaWatt with NaN values
Predicted_MegaWatt = [np.nan] * len(True_MegaWatt)

# Fill the predictions for all dates in TestData
start_idx = len(True_MegaWatt) - len(predicted_stock_price)
for i in range(len(predicted_stock_price)):
    Predicted_MegaWatt[start_idx + i] = predicted_stock_price[i][0]

Machine_Df = pd.DataFrame(data={
    "Date": dates,
    "TrueMegaWatt": True_MegaWatt,
    "PredictedMegaWatt": Predicted_MegaWatt
})

# Print the final DataFrame with predictions
print("Final Machine_Df with predictions:")
print(Machine_Df)
